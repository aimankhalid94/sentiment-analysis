{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"restaurant review comments.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turn off betul kedai makan bancuh air tak seda...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mende tah aku makan tadi. Tak sedap. *sebab bo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@nikasyrvf Mestii, sini kedai makan bukan seda...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tapi milo dekat fast food restaurant tak sedap...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semua makanan bau tengik. Loya tekak dibuatnya...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  senti\n",
       "0  turn off betul kedai makan bancuh air tak seda...     -1\n",
       "1  Mende tah aku makan tadi. Tak sedap. *sebab bo...     -1\n",
       "2  @nikasyrvf Mestii, sini kedai makan bukan seda...     -1\n",
       "3  Tapi milo dekat fast food restaurant tak sedap...     -1\n",
       "4  Semua makanan bau tengik. Loya tekak dibuatnya...     -1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    280\n",
       "-1    183\n",
       " 0    137\n",
       "Name: senti, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count = df['senti'].value_counts()\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of reviews ')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array(class_count.index)\n",
    "y = np.array(class_count.values)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x,y)\n",
    "plt.xlabel('Sentiment ')\n",
    "plt.ylabel('Number of reviews ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), tokenizer=tokenizer.tokenize)\n",
    "vectorizer.fit(df['tweet'])\n",
    "train_vectorized = vectorizer.transform(df['tweet'])\n",
    "# test_vectorized = vectorizer.transform(test['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['senti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_val, y_train , y_val = train_test_split(train_vectorized,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.14      0.62      0.23         8\n",
      "           0       0.03      1.00      0.05         1\n",
      "           1       0.98      0.42      0.59       111\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       120\n",
      "   macro avg       0.38      0.68      0.29       120\n",
      "weighted avg       0.92      0.44      0.56       120\n",
      "\n",
      "0.44166666666666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "ovr = OneVsRestClassifier(lr)\n",
    "ovr.fit(x_train,y_train)\n",
    "print(classification_report( ovr.predict(x_val) , y_val))\n",
    "print(accuracy_score( ovr.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.71      0.63        28\n",
      "           0       0.14      0.71      0.23         7\n",
      "           1       0.90      0.51      0.65        85\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       120\n",
      "   macro avg       0.53      0.64      0.50       120\n",
      "weighted avg       0.77      0.57      0.62       120\n",
      "\n",
      "0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(x_train,y_train)\n",
    "print(classification_report( svm.predict(x_val) , y_val))\n",
    "print(accuracy_score( svm.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.08      0.75      0.15         4\n",
      "           0       0.03      1.00      0.05         1\n",
      "           1       1.00      0.42      0.59       115\n",
      "\n",
      "   micro avg       0.43      0.43      0.43       120\n",
      "   macro avg       0.37      0.72      0.26       120\n",
      "weighted avg       0.96      0.43      0.57       120\n",
      "\n",
      "0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train,y_train)\n",
    "print(classification_report( mnb.predict(x_val) , y_val))\n",
    "print(accuracy_score( mnb.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malay_stopwords import stopwords, stopwords_1, _list_laugh\n",
    "from malay_normalization import rules_normalizer, sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing normalization\n",
    "def _dict_replace(wordlist, _dict):\n",
    "        return [_dict.get(w, w) for w in wordlist]\n",
    "\n",
    "def cleaning2(e_texts,rules):\n",
    "    text1 = e_texts.split()   \n",
    "    text1 = _dict_replace(text1, rules)\n",
    "    text1 = ' '.join(text1)\n",
    "    return text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing removing stopwords & symbol\n",
    "import re\n",
    "STOPWORDS = set(stopwords + stopwords_1 + _list_laugh)\n",
    "def clean_tweet(tweet):\n",
    "    comments = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|[^a-zA-Z#]\",\" \",str(tweet)).split())\n",
    "    comments = comments.lower().split()\n",
    "    comments = ' '.join([word for word in comments if word not in STOPWORDS])\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>senti</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turn off betul kedai makan bancuh air tak seda...</td>\n",
       "      <td>-1</td>\n",
       "      <td>turn off makan bancuh air tak sedap ni tak pay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mende tah aku makan tadi. Tak sedap. *sebab bo...</td>\n",
       "      <td>-1</td>\n",
       "      <td>mende tah makan tak sedap claim makan mengarut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@nikasyrvf Mestii, sini kedai makan bukan seda...</td>\n",
       "      <td>-1</td>\n",
       "      <td>mestii makan bukan sedap haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tapi milo dekat fast food restaurant tak sedap...</td>\n",
       "      <td>-1</td>\n",
       "      <td>milo fast food restaurant tak sedap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semua makanan bau tengik. Loya tekak dibuatnya...</td>\n",
       "      <td>-1</td>\n",
       "      <td>bau tengik loya tekak ape teruk peel demam pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  senti  \\\n",
       "0  turn off betul kedai makan bancuh air tak seda...     -1   \n",
       "1  Mende tah aku makan tadi. Tak sedap. *sebab bo...     -1   \n",
       "2  @nikasyrvf Mestii, sini kedai makan bukan seda...     -1   \n",
       "3  Tapi milo dekat fast food restaurant tak sedap...     -1   \n",
       "4  Semua makanan bau tengik. Loya tekak dibuatnya...     -1   \n",
       "\n",
       "                                              tweets  \n",
       "0  turn off makan bancuh air tak sedap ni tak pay...  \n",
       "1     mende tah makan tak sedap claim makan mengarut  \n",
       "2                      mestii makan bukan sedap haha  \n",
       "3                milo fast food restaurant tak sedap  \n",
       "4  bau tengik loya tekak ape teruk peel demam pre...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m=df\n",
    "import numpy as np\n",
    "df_m['tweets']=np.array([clean_tweet(text) for text in df.tweet])\n",
    "df_m.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>senti</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turn off betul kedai makan bancuh air tak seda...</td>\n",
       "      <td>-1</td>\n",
       "      <td>turn off makan bancuh air tak sedap ini tak pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mende tah aku makan tadi. Tak sedap. *sebab bo...</td>\n",
       "      <td>-1</td>\n",
       "      <td>mende entah makan tak sedap claim makan mengarut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@nikasyrvf Mestii, sini kedai makan bukan seda...</td>\n",
       "      <td>-1</td>\n",
       "      <td>mestii makan bukan sedap haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tapi milo dekat fast food restaurant tak sedap...</td>\n",
       "      <td>-1</td>\n",
       "      <td>milo fast food restaurant tak sedap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semua makanan bau tengik. Loya tekak dibuatnya...</td>\n",
       "      <td>-1</td>\n",
       "      <td>bau tengik loya tekak apa teruk peel demam pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  senti  \\\n",
       "0  turn off betul kedai makan bancuh air tak seda...     -1   \n",
       "1  Mende tah aku makan tadi. Tak sedap. *sebab bo...     -1   \n",
       "2  @nikasyrvf Mestii, sini kedai makan bukan seda...     -1   \n",
       "3  Tapi milo dekat fast food restaurant tak sedap...     -1   \n",
       "4  Semua makanan bau tengik. Loya tekak dibuatnya...     -1   \n",
       "\n",
       "                                              tweets  \n",
       "0  turn off makan bancuh air tak sedap ini tak pa...  \n",
       "1   mende entah makan tak sedap claim makan mengarut  \n",
       "2                      mestii makan bukan sedap haha  \n",
       "3                milo fast food restaurant tak sedap  \n",
       "4  bau tengik loya tekak apa teruk peel demam pre...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets']=np.array([cleaning2(text,rules_normalizer) for text in df.tweets])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>senti</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turn off betul kedai makan bancuh air tak seda...</td>\n",
       "      <td>-1</td>\n",
       "      <td>turn off makan bancuh air tak sedap ini tak pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mende tah aku makan tadi. Tak sedap. *sebab bo...</td>\n",
       "      <td>-1</td>\n",
       "      <td>mende entah makan tak sedap claim makan mengarut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@nikasyrvf Mestii, sini kedai makan bukan seda...</td>\n",
       "      <td>-1</td>\n",
       "      <td>mestii makan bukan sedap haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tapi milo dekat fast food restaurant tak sedap...</td>\n",
       "      <td>-1</td>\n",
       "      <td>milo fast food restaurant tak sedap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semua makanan bau tengik. Loya tekak dibuatnya...</td>\n",
       "      <td>-1</td>\n",
       "      <td>bau tengik loya tekak apa teruk peel demam pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  senti  \\\n",
       "0  turn off betul kedai makan bancuh air tak seda...     -1   \n",
       "1  Mende tah aku makan tadi. Tak sedap. *sebab bo...     -1   \n",
       "2  @nikasyrvf Mestii, sini kedai makan bukan seda...     -1   \n",
       "3  Tapi milo dekat fast food restaurant tak sedap...     -1   \n",
       "4  Semua makanan bau tengik. Loya tekak dibuatnya...     -1   \n",
       "\n",
       "                                              tweets  \n",
       "0  turn off makan bancuh air tak sedap ini tak pa...  \n",
       "1   mende entah makan tak sedap claim makan mengarut  \n",
       "2                      mestii makan bukan sedap haha  \n",
       "3                milo fast food restaurant tak sedap  \n",
       "4  bau tengik loya tekak apa teruk peel demam pre...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets']=np.array([cleaning2(text,sounds) for text in df.tweets])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tokenizer_m = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_m = TfidfVectorizer(ngram_range=(1, 3), tokenizer=tokenizer_m.tokenize)\n",
    "vectorizer_m.fit(df_m['tweets'])\n",
    "train_vectorized_m = vectorizer_m.transform(df_m['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m=df_m['senti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_m , x_val_m, y_train_m , y_val_m = train_test_split(train_vectorized_m,y_m,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.30      0.86      0.44        14\n",
      "           0       0.04      1.00      0.07         1\n",
      "           1       1.00      0.50      0.67       105\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       120\n",
      "   macro avg       0.45      0.79      0.40       120\n",
      "weighted avg       0.91      0.55      0.64       120\n",
      "\n",
      "0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_m = LogisticRegression()\n",
    "ovr_m = OneVsRestClassifier(lr_m)\n",
    "ovr_m.fit(x_train_m,y_train_m)\n",
    "print(classification_report( ovr_m.predict(x_val_m) , y_val_m))\n",
    "print(accuracy_score( ovr_m.predict(x_val_m) , y_val_m ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.88      0.78        32\n",
      "           0       0.26      0.88      0.40         8\n",
      "           1       0.98      0.65      0.78        80\n",
      "\n",
      "   micro avg       0.72      0.72      0.73       120\n",
      "   macro avg       0.65      0.80      0.65       120\n",
      "weighted avg       0.86      0.72      0.76       120\n",
      "\n",
      "0.725\n"
     ]
    }
   ],
   "source": [
    "svm_m = LinearSVC()\n",
    "svm_m.fit(x_train_m,y_train_m)\n",
    "print(classification_report( svm_m.predict(x_val_m) , y_val_m))\n",
    "print(accuracy_score( svm_m.predict(x_val_m) , y_val_m ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
